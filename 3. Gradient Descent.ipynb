{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent(경사하강법)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Gradient Descent Algorithm(경사하강법 알고리즘)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 What is 'learning'?('학습'이란 무엇인가?)\n",
    "- 학습: 손실($loss$)을 최소화 시키는 가중치($w$)를 찾는 것\n",
    "\n",
    "$$ \\operatorname{argmin}_w loss(w) $$\n",
    "\n",
    "- GD(Gradient Descent, 경사하강법)는 가중치($w$)를 찾는 방법중 하나 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Graph of GD(그래프) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![3_GD](slides/이미지/3_GD.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 개념: 가중치 $w$를 계속 업데이트 시켜 Global loss minimum를 찾는 것\n",
    "- 목표: Global loss minimum 찾기\n",
    "- Gradient(경사): 미분값\n",
    "- Gradient(경사) 구하는 법: 모델을 가중치로 미분(derivative)\n",
    "- GD 적용 방법\n",
    "    1. 임의의 초기값을 준다(initial weight).\n",
    "    2. Gradient(경사)를 계산한 후 방향을 설정한다.\n",
    "    3. Gradient에 Learning Rate($\\alpha$)를 곱하고 가중치($w$)에 업데이트 해준다.\n",
    "    4. 위에서 업데이트된 가중치를 적용한 후 새로운 계산을 한다.\n",
    "    5. 위의 과정을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Code Practice: GD Implement(경사하강법 적용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data & Model Design(데이터 & 모델 정의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 데이터 \n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "# 가중치 초기값(initial weight) 주기\n",
    "w = 1.0 # a random guess: random value\n",
    "w_2 = 1.0 # a random guess: random value\n",
    "\n",
    "b = 0 # bias\n",
    "\n",
    "# 1. our forward pass model(기본 모델 정의)\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "# 2. Loss function(손실 함수 정의)\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# 3. Compute gradient(경사 계산법 정의)\n",
    "def gradient(x, y): #d_loss/d_w\n",
    "    return 2 * x * (x * w - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training: Updating weight(훈련: 가중치 업데이트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0\n",
      "\tgrad:  1.0 2.0 -2.0\n",
      "\tgrad:  2.0 4.0 -7.84\n",
      "\tgrad:  3.0 6.0 -16.2288\n",
      "progress: 0 w= 1.260688 loss= 4.919240100095999\n",
      "\tgrad:  1.0 2.0 -1.478624\n",
      "\tgrad:  2.0 4.0 -5.796206079999999\n",
      "\tgrad:  3.0 6.0 -11.998146585599997\n",
      "progress: 1 w= 1.453417766656 loss= 2.688769240265834\n",
      "\tgrad:  1.0 2.0 -1.093164466688\n",
      "\tgrad:  2.0 4.0 -4.285204709416961\n",
      "\tgrad:  3.0 6.0 -8.87037374849311\n",
      "progress: 2 w= 1.5959051959019805 loss= 1.4696334962911515\n",
      "\tgrad:  1.0 2.0 -0.8081896081960389\n",
      "\tgrad:  2.0 4.0 -3.1681032641284723\n",
      "\tgrad:  3.0 6.0 -6.557973756745939\n",
      "progress: 3 w= 1.701247862192685 loss= 0.8032755585999681\n",
      "\tgrad:  1.0 2.0 -0.59750427561463\n",
      "\tgrad:  2.0 4.0 -2.3422167604093502\n",
      "\tgrad:  3.0 6.0 -4.848388694047353\n",
      "progress: 4 w= 1.7791289594933983 loss= 0.43905614881022015\n",
      "\tgrad:  1.0 2.0 -0.44174208101320334\n",
      "\tgrad:  2.0 4.0 -1.7316289575717576\n",
      "\tgrad:  3.0 6.0 -3.584471942173538\n",
      "progress: 5 w= 1.836707389300983 loss= 0.2399802903801062\n",
      "\tgrad:  1.0 2.0 -0.3265852213980338\n",
      "\tgrad:  2.0 4.0 -1.2802140678802925\n",
      "\tgrad:  3.0 6.0 -2.650043120512205\n",
      "progress: 6 w= 1.8792758133988885 loss= 0.1311689630744999\n",
      "\tgrad:  1.0 2.0 -0.241448373202223\n",
      "\tgrad:  2.0 4.0 -0.946477622952715\n",
      "\tgrad:  3.0 6.0 -1.9592086795121197\n",
      "progress: 7 w= 1.910747160155559 loss= 0.07169462478267678\n",
      "\tgrad:  1.0 2.0 -0.17850567968888198\n",
      "\tgrad:  2.0 4.0 -0.6997422643804168\n",
      "\tgrad:  3.0 6.0 -1.4484664872674653\n",
      "progress: 8 w= 1.9340143044689266 loss= 0.03918700813247573\n",
      "\tgrad:  1.0 2.0 -0.13197139106214673\n",
      "\tgrad:  2.0 4.0 -0.5173278529636143\n",
      "\tgrad:  3.0 6.0 -1.0708686556346834\n",
      "progress: 9 w= 1.9512159834655312 loss= 0.021418922423117836\n",
      "\tgrad:  1.0 2.0 -0.09756803306893769\n",
      "\tgrad:  2.0 4.0 -0.38246668963023644\n",
      "\tgrad:  3.0 6.0 -0.7917060475345892\n",
      "progress: 10 w= 1.9639333911678687 loss= 0.01170720245384975\n",
      "\tgrad:  1.0 2.0 -0.07213321766426262\n",
      "\tgrad:  2.0 4.0 -0.2827622132439096\n",
      "\tgrad:  3.0 6.0 -0.5853177814148953\n",
      "progress: 11 w= 1.9733355232910992 loss= 0.006398948863435593\n",
      "\tgrad:  1.0 2.0 -0.05332895341780164\n",
      "\tgrad:  2.0 4.0 -0.2090494973977819\n",
      "\tgrad:  3.0 6.0 -0.4327324596134101\n",
      "progress: 12 w= 1.9802866323953892 loss= 0.003497551760830656\n",
      "\tgrad:  1.0 2.0 -0.039426735209221686\n",
      "\tgrad:  2.0 4.0 -0.15455280202014876\n",
      "\tgrad:  3.0 6.0 -0.3199243001817109\n",
      "progress: 13 w= 1.9854256707695 loss= 0.001911699652671057\n",
      "\tgrad:  1.0 2.0 -0.02914865846100012\n",
      "\tgrad:  2.0 4.0 -0.11426274116712065\n",
      "\tgrad:  3.0 6.0 -0.2365238742159388\n",
      "progress: 14 w= 1.9892250235079405 loss= 0.0010449010656399273\n",
      "\tgrad:  1.0 2.0 -0.021549952984118992\n",
      "\tgrad:  2.0 4.0 -0.08447581569774698\n",
      "\tgrad:  3.0 6.0 -0.17486493849433593\n",
      "progress: 15 w= 1.9920339305797026 loss= 0.0005711243580809696\n",
      "\tgrad:  1.0 2.0 -0.015932138840594856\n",
      "\tgrad:  2.0 4.0 -0.062453984255132156\n",
      "\tgrad:  3.0 6.0 -0.12927974740812687\n",
      "progress: 16 w= 1.994110589284741 loss= 0.0003121664271570621\n",
      "\tgrad:  1.0 2.0 -0.011778821430517894\n",
      "\tgrad:  2.0 4.0 -0.046172980007630926\n",
      "\tgrad:  3.0 6.0 -0.09557806861579543\n",
      "progress: 17 w= 1.9956458879852805 loss= 0.0001706246229305199\n",
      "\tgrad:  1.0 2.0 -0.008708224029438938\n",
      "\tgrad:  2.0 4.0 -0.03413623819540135\n",
      "\tgrad:  3.0 6.0 -0.07066201306448505\n",
      "progress: 18 w= 1.9967809527381737 loss= 9.326038746484765e-05\n",
      "\tgrad:  1.0 2.0 -0.006438094523652627\n",
      "\tgrad:  2.0 4.0 -0.02523733053271826\n",
      "\tgrad:  3.0 6.0 -0.052241274202728505\n",
      "progress: 19 w= 1.9976201197307648 loss= 5.097447086306101e-05\n",
      "\tgrad:  1.0 2.0 -0.004759760538470381\n",
      "\tgrad:  2.0 4.0 -0.01865826131080439\n",
      "\tgrad:  3.0 6.0 -0.03862260091336722\n",
      "progress: 20 w= 1.998240525958391 loss= 2.7861740127856012e-05\n",
      "\tgrad:  1.0 2.0 -0.0035189480832178432\n",
      "\tgrad:  2.0 4.0 -0.01379427648621423\n",
      "\tgrad:  3.0 6.0 -0.028554152326460525\n",
      "progress: 21 w= 1.99869919972735 loss= 1.5228732143933469e-05\n",
      "\tgrad:  1.0 2.0 -0.002601600545300009\n",
      "\tgrad:  2.0 4.0 -0.01019827413757568\n",
      "\tgrad:  3.0 6.0 -0.021110427464781978\n",
      "progress: 22 w= 1.9990383027488265 loss= 8.323754426231206e-06\n",
      "\tgrad:  1.0 2.0 -0.001923394502346909\n",
      "\tgrad:  2.0 4.0 -0.007539706449199102\n",
      "\tgrad:  3.0 6.0 -0.01560719234984198\n",
      "progress: 23 w= 1.9992890056818404 loss= 4.549616284094891e-06\n",
      "\tgrad:  1.0 2.0 -0.0014219886363191492\n",
      "\tgrad:  2.0 4.0 -0.005574195454370212\n",
      "\tgrad:  3.0 6.0 -0.011538584590544687\n",
      "progress: 24 w= 1.999474353368653 loss= 2.486739429417538e-06\n",
      "\tgrad:  1.0 2.0 -0.0010512932626940419\n",
      "\tgrad:  2.0 4.0 -0.004121069589761106\n",
      "\tgrad:  3.0 6.0 -0.008530614050808794\n",
      "progress: 25 w= 1.9996113831376856 loss= 1.3592075910762856e-06\n",
      "\tgrad:  1.0 2.0 -0.0007772337246287897\n",
      "\tgrad:  2.0 4.0 -0.0030467562005451754\n",
      "\tgrad:  3.0 6.0 -0.006306785335127074\n",
      "progress: 26 w= 1.9997126908902887 loss= 7.429187207079447e-07\n",
      "\tgrad:  1.0 2.0 -0.0005746182194226179\n",
      "\tgrad:  2.0 4.0 -0.002252503420136165\n",
      "\tgrad:  3.0 6.0 -0.00466268207967957\n",
      "progress: 27 w= 1.9997875889274812 loss= 4.060661735575354e-07\n",
      "\tgrad:  1.0 2.0 -0.0004248221450375844\n",
      "\tgrad:  2.0 4.0 -0.0016653028085471533\n",
      "\tgrad:  3.0 6.0 -0.0034471768136938863\n",
      "progress: 28 w= 1.9998429619451539 loss= 2.2194855602869353e-07\n",
      "\tgrad:  1.0 2.0 -0.00031407610969225175\n",
      "\tgrad:  2.0 4.0 -0.0012311783499932005\n",
      "\tgrad:  3.0 6.0 -0.0025485391844828342\n",
      "progress: 29 w= 1.9998838998815958 loss= 1.213131374411496e-07\n",
      "\tgrad:  1.0 2.0 -0.00023220023680847746\n",
      "\tgrad:  2.0 4.0 -0.0009102249282886277\n",
      "\tgrad:  3.0 6.0 -0.0018841656015560204\n",
      "progress: 30 w= 1.9999141657892625 loss= 6.630760559646474e-08\n",
      "\tgrad:  1.0 2.0 -0.00017166842147497974\n",
      "\tgrad:  2.0 4.0 -0.0006729402121816719\n",
      "\tgrad:  3.0 6.0 -0.0013929862392156878\n",
      "progress: 31 w= 1.9999365417379913 loss= 3.624255915449335e-08\n",
      "\tgrad:  1.0 2.0 -0.0001269165240174175\n",
      "\tgrad:  2.0 4.0 -0.0004975127741477792\n",
      "\tgrad:  3.0 6.0 -0.0010298514424817995\n",
      "progress: 32 w= 1.9999530845453979 loss= 1.9809538924707548e-08\n",
      "\tgrad:  1.0 2.0 -9.383090920422887e-05\n",
      "\tgrad:  2.0 4.0 -0.00036781716408107457\n",
      "\tgrad:  3.0 6.0 -0.0007613815296476645\n",
      "progress: 33 w= 1.9999653148414271 loss= 1.0827542027017377e-08\n",
      "\tgrad:  1.0 2.0 -6.937031714571162e-05\n",
      "\tgrad:  2.0 4.0 -0.0002719316432120422\n",
      "\tgrad:  3.0 6.0 -0.0005628985014531906\n",
      "progress: 34 w= 1.999974356846045 loss= 5.9181421028034105e-09\n",
      "\tgrad:  1.0 2.0 -5.1286307909848006e-05\n",
      "\tgrad:  2.0 4.0 -0.00020104232700646207\n",
      "\tgrad:  3.0 6.0 -0.0004161576169003922\n",
      "progress: 35 w= 1.9999810417085633 loss= 3.2347513278475087e-09\n",
      "\tgrad:  1.0 2.0 -3.7916582873442906e-05\n",
      "\tgrad:  2.0 4.0 -0.0001486330048638962\n",
      "\tgrad:  3.0 6.0 -0.0003076703200690645\n",
      "progress: 36 w= 1.9999859839076413 loss= 1.7680576050779005e-09\n",
      "\tgrad:  1.0 2.0 -2.8032184717474706e-05\n",
      "\tgrad:  2.0 4.0 -0.0001098861640933535\n",
      "\tgrad:  3.0 6.0 -0.00022746435967313516\n",
      "progress: 37 w= 1.9999896377347262 loss= 9.6638887447731e-10\n",
      "\tgrad:  1.0 2.0 -2.0724530547688857e-05\n",
      "\tgrad:  2.0 4.0 -8.124015974608767e-05\n",
      "\tgrad:  3.0 6.0 -0.00016816713067413502\n",
      "progress: 38 w= 1.999992339052936 loss= 5.282109892545845e-10\n",
      "\tgrad:  1.0 2.0 -1.5321894128117464e-05\n",
      "\tgrad:  2.0 4.0 -6.006182498197177e-05\n",
      "\tgrad:  3.0 6.0 -0.00012432797771566584\n",
      "progress: 39 w= 1.9999943361699042 loss= 2.887107421958329e-10\n",
      "\tgrad:  1.0 2.0 -1.1327660191629008e-05\n",
      "\tgrad:  2.0 4.0 -4.4404427951505454e-05\n",
      "\tgrad:  3.0 6.0 -9.191716585732479e-05\n",
      "progress: 40 w= 1.9999958126624442 loss= 1.5780416225633037e-10\n",
      "\tgrad:  1.0 2.0 -8.37467511161094e-06\n",
      "\tgrad:  2.0 4.0 -3.282872643772805e-05\n",
      "\tgrad:  3.0 6.0 -6.795546372551087e-05\n",
      "progress: 41 w= 1.999996904251097 loss= 8.625295142578772e-11\n",
      "\tgrad:  1.0 2.0 -6.191497806007362e-06\n",
      "\tgrad:  2.0 4.0 -2.4270671399762023e-05\n",
      "\tgrad:  3.0 6.0 -5.0240289795056015e-05\n",
      "progress: 42 w= 1.999997711275687 loss= 4.71443308235547e-11\n",
      "\tgrad:  1.0 2.0 -4.5774486259198e-06\n",
      "\tgrad:  2.0 4.0 -1.794359861406747e-05\n",
      "\tgrad:  3.0 6.0 -3.714324913239864e-05\n",
      "progress: 43 w= 1.9999983079186507 loss= 2.5768253628059826e-11\n",
      "\tgrad:  1.0 2.0 -3.3841626985164908e-06\n",
      "\tgrad:  2.0 4.0 -1.326591777761621e-05\n",
      "\tgrad:  3.0 6.0 -2.7460449796734565e-05\n",
      "progress: 44 w= 1.9999987490239537 loss= 1.4084469615916932e-11\n",
      "\tgrad:  1.0 2.0 -2.5019520926150562e-06\n",
      "\tgrad:  2.0 4.0 -9.807652203264183e-06\n",
      "\tgrad:  3.0 6.0 -2.0301840059744336e-05\n",
      "progress: 45 w= 1.9999990751383971 loss= 7.698320862431846e-12\n",
      "\tgrad:  1.0 2.0 -1.8497232057157476e-06\n",
      "\tgrad:  2.0 4.0 -7.250914967116273e-06\n",
      "\tgrad:  3.0 6.0 -1.5009393983689279e-05\n",
      "progress: 46 w= 1.9999993162387186 loss= 4.20776540913866e-12\n",
      "\tgrad:  1.0 2.0 -1.3675225627451937e-06\n",
      "\tgrad:  2.0 4.0 -5.3606884460322135e-06\n",
      "\tgrad:  3.0 6.0 -1.109662508014253e-05\n",
      "progress: 47 w= 1.9999994944870796 loss= 2.299889814334344e-12\n",
      "\tgrad:  1.0 2.0 -1.0110258408246864e-06\n",
      "\tgrad:  2.0 4.0 -3.963221296032771e-06\n",
      "\tgrad:  3.0 6.0 -8.20386808086937e-06\n",
      "progress: 48 w= 1.9999996262682318 loss= 1.2570789110540446e-12\n",
      "\tgrad:  1.0 2.0 -7.474635363990956e-07\n",
      "\tgrad:  2.0 4.0 -2.930057062755509e-06\n",
      "\tgrad:  3.0 6.0 -6.065218119744031e-06\n",
      "progress: 49 w= 1.999999723695619 loss= 6.870969979249939e-13\n",
      "\tgrad:  1.0 2.0 -5.526087618612507e-07\n",
      "\tgrad:  2.0 4.0 -2.166226346744793e-06\n",
      "\tgrad:  3.0 6.0 -4.484088535150477e-06\n",
      "progress: 50 w= 1.9999997957248556 loss= 3.7555501141274804e-13\n",
      "\tgrad:  1.0 2.0 -4.08550288710785e-07\n",
      "\tgrad:  2.0 4.0 -1.6015171322436572e-06\n",
      "\tgrad:  3.0 6.0 -3.3151404608133817e-06\n",
      "progress: 51 w= 1.9999998489769344 loss= 2.052716967104274e-13\n",
      "\tgrad:  1.0 2.0 -3.020461312175371e-07\n",
      "\tgrad:  2.0 4.0 -1.1840208351543424e-06\n",
      "\tgrad:  3.0 6.0 -2.4509231284497446e-06\n",
      "progress: 52 w= 1.9999998883468353 loss= 1.1219786256679713e-13\n",
      "\tgrad:  1.0 2.0 -2.2330632942768602e-07\n",
      "\tgrad:  2.0 4.0 -8.753608113920563e-07\n",
      "\tgrad:  3.0 6.0 -1.811996877876254e-06\n",
      "progress: 53 w= 1.9999999174534755 loss= 6.132535848018759e-14\n",
      "\tgrad:  1.0 2.0 -1.6509304900935717e-07\n",
      "\tgrad:  2.0 4.0 -6.471647520100987e-07\n",
      "\tgrad:  3.0 6.0 -1.3396310407642886e-06\n",
      "progress: 54 w= 1.999999938972364 loss= 3.351935118167793e-14\n",
      "\tgrad:  1.0 2.0 -1.220552721115098e-07\n",
      "\tgrad:  2.0 4.0 -4.784566662863199e-07\n",
      "\tgrad:  3.0 6.0 -9.904052991061008e-07\n",
      "progress: 55 w= 1.9999999548815364 loss= 1.8321081844499955e-14\n",
      "\tgrad:  1.0 2.0 -9.023692726373156e-08\n",
      "\tgrad:  2.0 4.0 -3.5372875473171916e-07\n",
      "\tgrad:  3.0 6.0 -7.322185204827747e-07\n",
      "progress: 56 w= 1.9999999666433785 loss= 1.0013977760018664e-14\n",
      "\tgrad:  1.0 2.0 -6.671324292994996e-08\n",
      "\tgrad:  2.0 4.0 -2.615159129248923e-07\n",
      "\tgrad:  3.0 6.0 -5.413379398078177e-07\n",
      "progress: 57 w= 1.9999999753390494 loss= 5.473462367088053e-15\n",
      "\tgrad:  1.0 2.0 -4.932190122985958e-08\n",
      "\tgrad:  2.0 4.0 -1.9334185274999527e-07\n",
      "\tgrad:  3.0 6.0 -4.002176350326181e-07\n",
      "progress: 58 w= 1.9999999817678633 loss= 2.991697274308627e-15\n",
      "\tgrad:  1.0 2.0 -3.6464273378555845e-08\n",
      "\tgrad:  2.0 4.0 -1.429399514307761e-07\n",
      "\tgrad:  3.0 6.0 -2.9588569994132286e-07\n",
      "progress: 59 w= 1.9999999865207625 loss= 1.6352086111474931e-15\n",
      "\tgrad:  1.0 2.0 -2.6958475007887728e-08\n",
      "\tgrad:  2.0 4.0 -1.0567722164012139e-07\n",
      "\tgrad:  3.0 6.0 -2.1875184863517916e-07\n",
      "progress: 60 w= 1.999999990034638 loss= 8.937759877335403e-16\n",
      "\tgrad:  1.0 2.0 -1.993072418216002e-08\n",
      "\tgrad:  2.0 4.0 -7.812843882959442e-08\n",
      "\tgrad:  3.0 6.0 -1.617258700292723e-07\n",
      "progress: 61 w= 1.9999999926324883 loss= 4.885220495987371e-16\n",
      "\tgrad:  1.0 2.0 -1.473502342363986e-08\n",
      "\tgrad:  2.0 4.0 -5.7761292637792394e-08\n",
      "\tgrad:  3.0 6.0 -1.195658771990793e-07\n",
      "progress: 62 w= 1.99999999455311 loss= 2.670175009618106e-16\n",
      "\tgrad:  1.0 2.0 -1.0893780100218464e-08\n",
      "\tgrad:  2.0 4.0 -4.270361841918202e-08\n",
      "\tgrad:  3.0 6.0 -8.839649012770678e-08\n",
      "progress: 63 w= 1.9999999959730488 loss= 1.4594702493172377e-16\n",
      "\tgrad:  1.0 2.0 -8.05390243385773e-09\n",
      "\tgrad:  2.0 4.0 -3.1571296688071016e-08\n",
      "\tgrad:  3.0 6.0 -6.53525820126788e-08\n",
      "progress: 64 w= 1.9999999970228268 loss= 7.977204100704301e-17\n",
      "\tgrad:  1.0 2.0 -5.9543463493128e-09\n",
      "\tgrad:  2.0 4.0 -2.334103754719763e-08\n",
      "\tgrad:  3.0 6.0 -4.8315948575350376e-08\n",
      "progress: 65 w= 1.9999999977989402 loss= 4.360197735196887e-17\n",
      "\tgrad:  1.0 2.0 -4.402119557767037e-09\n",
      "\tgrad:  2.0 4.0 -1.725630838222969e-08\n",
      "\tgrad:  3.0 6.0 -3.5720557178819945e-08\n",
      "progress: 66 w= 1.9999999983727301 loss= 2.3832065197304227e-17\n",
      "\tgrad:  1.0 2.0 -3.254539748809293e-09\n",
      "\tgrad:  2.0 4.0 -1.2757796596929438e-08\n",
      "\tgrad:  3.0 6.0 -2.6408640607655798e-08\n",
      "progress: 67 w= 1.9999999987969397 loss= 1.3026183953845832e-17\n",
      "\tgrad:  1.0 2.0 -2.406120636067044e-09\n",
      "\tgrad:  2.0 4.0 -9.431992964437086e-09\n",
      "\tgrad:  3.0 6.0 -1.9524227568012975e-08\n",
      "progress: 68 w= 1.999999999110563 loss= 7.11988308874388e-18\n",
      "\tgrad:  1.0 2.0 -1.7788739370416806e-09\n",
      "\tgrad:  2.0 4.0 -6.97318647269185e-09\n",
      "\tgrad:  3.0 6.0 -1.4434496264925656e-08\n",
      "progress: 69 w= 1.9999999993424284 loss= 3.89160224698574e-18\n",
      "\tgrad:  1.0 2.0 -1.3151431055291596e-09\n",
      "\tgrad:  2.0 4.0 -5.155360582875801e-09\n",
      "\tgrad:  3.0 6.0 -1.067159693945996e-08\n",
      "progress: 70 w= 1.9999999995138495 loss= 2.1270797208746147e-18\n",
      "\tgrad:  1.0 2.0 -9.72300906454393e-10\n",
      "\tgrad:  2.0 4.0 -3.811418736177075e-09\n",
      "\tgrad:  3.0 6.0 -7.88963561149103e-09\n",
      "progress: 71 w= 1.9999999996405833 loss= 1.1626238773828175e-18\n",
      "\tgrad:  1.0 2.0 -7.18833437218791e-10\n",
      "\tgrad:  2.0 4.0 -2.8178277489132597e-09\n",
      "\tgrad:  3.0 6.0 -5.832902161273523e-09\n",
      "progress: 72 w= 1.999999999734279 loss= 6.354692062078993e-19\n",
      "\tgrad:  1.0 2.0 -5.314420015167798e-10\n",
      "\tgrad:  2.0 4.0 -2.0832526814729135e-09\n",
      "\tgrad:  3.0 6.0 -4.31233715403323e-09\n",
      "progress: 73 w= 1.9999999998035491 loss= 3.4733644793346653e-19\n",
      "\tgrad:  1.0 2.0 -3.92901711165905e-10\n",
      "\tgrad:  2.0 4.0 -1.5401742103904326e-09\n",
      "\tgrad:  3.0 6.0 -3.188159070077745e-09\n",
      "progress: 74 w= 1.9999999998547615 loss= 1.8984796531526204e-19\n",
      "\tgrad:  1.0 2.0 -2.9047697580608656e-10\n",
      "\tgrad:  2.0 4.0 -1.1386696030513122e-09\n",
      "\tgrad:  3.0 6.0 -2.3570478902001923e-09\n",
      "progress: 75 w= 1.9999999998926234 loss= 1.0376765851119951e-19\n",
      "\tgrad:  1.0 2.0 -2.1475310418850313e-10\n",
      "\tgrad:  2.0 4.0 -8.418314934033333e-10\n",
      "\tgrad:  3.0 6.0 -1.7425900722400911e-09\n",
      "progress: 76 w= 1.9999999999206153 loss= 5.671751114309842e-20\n",
      "\tgrad:  1.0 2.0 -1.5876944203796484e-10\n",
      "\tgrad:  2.0 4.0 -6.223768167501476e-10\n",
      "\tgrad:  3.0 6.0 -1.2883241140571045e-09\n",
      "progress: 77 w= 1.9999999999413098 loss= 3.100089617511693e-20\n",
      "\tgrad:  1.0 2.0 -1.17380327679939e-10\n",
      "\tgrad:  2.0 4.0 -4.601314884666863e-10\n",
      "\tgrad:  3.0 6.0 -9.524754318590567e-10\n",
      "progress: 78 w= 1.9999999999566096 loss= 1.6944600977692705e-20\n",
      "\tgrad:  1.0 2.0 -8.678080476443029e-11\n",
      "\tgrad:  2.0 4.0 -3.4018121652934497e-10\n",
      "\tgrad:  3.0 6.0 -7.041780492045291e-10\n",
      "progress: 79 w= 1.9999999999679208 loss= 9.2616919156479e-21\n",
      "\tgrad:  1.0 2.0 -6.415845632545825e-11\n",
      "\tgrad:  2.0 4.0 -2.5150193039280566e-10\n",
      "\tgrad:  3.0 6.0 -5.206075570640678e-10\n",
      "progress: 80 w= 1.9999999999762834 loss= 5.062350511130293e-21\n",
      "\tgrad:  1.0 2.0 -4.743316850408519e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  2.0 4.0 -1.8593837580738182e-10\n",
      "\tgrad:  3.0 6.0 -3.8489211817704927e-10\n",
      "progress: 81 w= 1.999999999982466 loss= 2.7669155644059242e-21\n",
      "\tgrad:  1.0 2.0 -3.5067948545020045e-11\n",
      "\tgrad:  2.0 4.0 -1.3746692673066718e-10\n",
      "\tgrad:  3.0 6.0 -2.845563784603655e-10\n",
      "progress: 82 w= 1.9999999999870368 loss= 1.5124150106147723e-21\n",
      "\tgrad:  1.0 2.0 -2.5926372160256506e-11\n",
      "\tgrad:  2.0 4.0 -1.0163070385260653e-10\n",
      "\tgrad:  3.0 6.0 -2.1037571684701106e-10\n",
      "progress: 83 w= 1.999999999990416 loss= 8.26683933105326e-22\n",
      "\tgrad:  1.0 2.0 -1.9167778475548403e-11\n",
      "\tgrad:  2.0 4.0 -7.51381179497912e-11\n",
      "\tgrad:  3.0 6.0 -1.5553425214420713e-10\n",
      "progress: 84 w= 1.9999999999929146 loss= 4.518126871054872e-22\n",
      "\tgrad:  1.0 2.0 -1.4170886686315498e-11\n",
      "\tgrad:  2.0 4.0 -5.555023108172463e-11\n",
      "\tgrad:  3.0 6.0 -1.1499068364173581e-10\n",
      "progress: 85 w= 1.9999999999947617 loss= 2.469467919185614e-22\n",
      "\tgrad:  1.0 2.0 -1.0476508549572827e-11\n",
      "\tgrad:  2.0 4.0 -4.106759377009439e-11\n",
      "\tgrad:  3.0 6.0 -8.500933290633839e-11\n",
      "progress: 86 w= 1.9999999999961273 loss= 1.349840097651456e-22\n",
      "\tgrad:  1.0 2.0 -7.745359908994942e-12\n",
      "\tgrad:  2.0 4.0 -3.036149109902908e-11\n",
      "\tgrad:  3.0 6.0 -6.285105769165966e-11\n",
      "progress: 87 w= 1.999999999997137 loss= 7.376551550022107e-23\n",
      "\tgrad:  1.0 2.0 -5.726086271806707e-12\n",
      "\tgrad:  2.0 4.0 -2.2446045022661565e-11\n",
      "\tgrad:  3.0 6.0 -4.646416584819235e-11\n",
      "progress: 88 w= 1.9999999999978835 loss= 4.031726170507742e-23\n",
      "\tgrad:  1.0 2.0 -4.233058348290797e-12\n",
      "\tgrad:  2.0 4.0 -1.659294923683774e-11\n",
      "\tgrad:  3.0 6.0 -3.4351188560322043e-11\n",
      "progress: 89 w= 1.9999999999984353 loss= 2.2033851437431755e-23\n",
      "\tgrad:  1.0 2.0 -3.1294966618133913e-12\n",
      "\tgrad:  2.0 4.0 -1.226752033289813e-11\n",
      "\tgrad:  3.0 6.0 -2.539835008974478e-11\n",
      "progress: 90 w= 1.9999999999988431 loss= 1.2047849775995315e-23\n",
      "\tgrad:  1.0 2.0 -2.3137047833188262e-12\n",
      "\tgrad:  2.0 4.0 -9.070078021977679e-12\n",
      "\tgrad:  3.0 6.0 -1.8779644506139448e-11\n",
      "progress: 91 w= 1.9999999999991447 loss= 6.5840863393251405e-24\n",
      "\tgrad:  1.0 2.0 -1.7106316363424412e-12\n",
      "\tgrad:  2.0 4.0 -6.7057470687359455e-12\n",
      "\tgrad:  3.0 6.0 -1.3882228699912957e-11\n",
      "progress: 92 w= 1.9999999999993676 loss= 3.5991747246272455e-24\n",
      "\tgrad:  1.0 2.0 -1.2647660696529783e-12\n",
      "\tgrad:  2.0 4.0 -4.957811938766099e-12\n",
      "\tgrad:  3.0 6.0 -1.0263789818054647e-11\n",
      "progress: 93 w= 1.9999999999995324 loss= 1.969312363793734e-24\n",
      "\tgrad:  1.0 2.0 -9.352518759442319e-13\n",
      "\tgrad:  2.0 4.0 -3.666400516522117e-12\n",
      "\tgrad:  3.0 6.0 -7.58859641791787e-12\n",
      "progress: 94 w= 1.9999999999996543 loss= 1.0761829795642296e-24\n",
      "\tgrad:  1.0 2.0 -6.914468997365475e-13\n",
      "\tgrad:  2.0 4.0 -2.7107205369247822e-12\n",
      "\tgrad:  3.0 6.0 -5.611511255665391e-12\n",
      "progress: 95 w= 1.9999999999997444 loss= 5.875191475205477e-25\n",
      "\tgrad:  1.0 2.0 -5.111466805374221e-13\n",
      "\tgrad:  2.0 4.0 -2.0037305148434825e-12\n",
      "\tgrad:  3.0 6.0 -4.1460168631601846e-12\n",
      "progress: 96 w= 1.999999999999811 loss= 3.2110109830478153e-25\n",
      "\tgrad:  1.0 2.0 -3.779199175824033e-13\n",
      "\tgrad:  2.0 4.0 -1.4814816040598089e-12\n",
      "\tgrad:  3.0 6.0 -3.064215547965432e-12\n",
      "progress: 97 w= 1.9999999999998603 loss= 1.757455879087579e-25\n",
      "\tgrad:  1.0 2.0 -2.793321129956894e-13\n",
      "\tgrad:  2.0 4.0 -1.0942358130705543e-12\n",
      "\tgrad:  3.0 6.0 -2.2648549702353193e-12\n",
      "progress: 98 w= 1.9999999999998967 loss= 9.608404711682446e-26\n",
      "\tgrad:  1.0 2.0 -2.0650148258027912e-13\n",
      "\tgrad:  2.0 4.0 -8.100187187665142e-13\n",
      "\tgrad:  3.0 6.0 -1.6786572132332367e-12\n",
      "progress: 99 w= 1.9999999999999236 loss= 5.250973729513143e-26\n",
      "predict(after training) 4 hours 7.9999999999996945\n"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "print(\"predict (before training)\", 4, forward(4))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100): # epoch: 훈련 반복 횟수\n",
    "    for x_val, y_val in zip(x_data, y_data): # 훈련 데이터 가져오기\n",
    "        grad = gradient(x_val, y_val) # 경사 정의\n",
    "        w = w - 0.01 * grad # where we have to update # Learning Rate 0.01 설정\n",
    "        print(\"\\tgrad: \", x_val, y_val, grad)\n",
    "        l = loss(x_val, y_val) # 손실 계산\n",
    "\n",
    "    print(\"progress:\", epoch, \"w=\", w, \"loss=\", l)\n",
    "\n",
    "# After training\n",
    "print(\"predict(after training)\", \"4 hours\", forward(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.2.2: Compute and implement gradient\n",
    "\n",
    "# gradient\n",
    "def gradient_1(x, y):\n",
    "    return 2*x*(x*x*w_2+x*w+b-y) \n",
    "\n",
    "def gradient_2(x, y):\n",
    "    return 2*x*x*(x*x*w_2+x*w+b-y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 7.9999999999996945\n",
      "\tgrad:  1.0 2.0 1.9999999999998472 1.9599999999998499\n",
      "\tgrad:  2.0 4.0 15.526399999999427 28.56857599999894\n",
      "\tgrad:  3.0 6.0 34.359816959999414 84.52514972159857\n",
      "progress: 0 w= 1.4811378303999367 w_2= -0.15053725721597355 loss= 2.4229615593787632\n",
      "\tgrad:  1.0 2.0 -1.3387988536320736 -1.312022876559432\n",
      "\tgrad:  2.0 4.0 -6.242465903716006 -11.486137262837453\n",
      "\tgrad:  3.0 6.0 -9.192896810866742 -22.61452615473218\n",
      "progress: 1 w= 1.648879446082085 w_2= 0.2035896057253171 loss= 1.1095707904526109\n",
      "\tgrad:  1.0 2.0 -0.29506189638519587 -0.28916065845749195\n",
      "\tgrad:  2.0 4.0 0.5183399173257683 0.9537454478794132\n",
      "\tgrad:  3.0 6.0 4.274602908587514 10.515523155125265\n",
      "progress: 2 w= 1.603900636786804 w_2= 0.0917885262798452 loss= 1.412052349841094\n",
      "\tgrad:  1.0 2.0 -0.6086216738667014 -0.5964492403893673\n",
      "\tgrad:  2.0 4.0 -1.5560568728564093 -2.863144646055794\n",
      "\tgrad:  3.0 6.0 0.08461471836465506 0.20815220717705785\n",
      "progress: 3 w= 1.6247012750703886 w_2= 0.12430294307252622 loss= 1.267642196404129\n",
      "\tgrad:  1.0 2.0 -0.5019915637141703 -0.49195173243988677\n",
      "\tgrad:  2.0 4.0 -0.8946711079889553 -1.646194838699678\n",
      "\tgrad:  3.0 6.0 1.3629803065053387 3.3529315540031455\n",
      "progress: 4 w= 1.6250380987223665 w_2= 0.1121550932438904 loss= 1.2653678466876395\n",
      "\tgrad:  1.0 2.0 -0.5256136160674862 -0.5151013437461365\n",
      "\tgrad:  2.0 4.0 -1.0807484140340406 -1.9885770818226334\n",
      "\tgrad:  3.0 6.0 0.9481923273980897 2.3325531253993006\n",
      "progress: 5 w= 1.631619795749401 w_2= 0.11386634624558511 loss= 1.221335773953418\n",
      "\tgrad:  1.0 2.0 -0.5090277160100278 -0.49884716168982735\n",
      "\tgrad:  2.0 4.0 -1.0046423309242556 -1.8485418889006304\n",
      "\tgrad:  3.0 6.0 1.057989716517831 2.6026547026338704\n",
      "progress: 6 w= 1.6361765990535655 w_2= 0.111313689725151 loss= 1.1913072036860708\n",
      "\tgrad:  1.0 2.0 -0.505019422442567 -0.49491903399371573\n",
      "\tgrad:  2.0 4.0 -1.009979572734661 -1.8583624138317774\n",
      "\tgrad:  3.0 6.0 1.0055898290799963 2.4737509795368027\n",
      "progress: 7 w= 1.6412706907145378 w_2= 0.11010899440803791 loss= 1.1581804560638227\n",
      "\tgrad:  1.0 2.0 -0.4972406297548484 -0.48729581715975145\n",
      "\tgrad:  2.0 4.0 -0.9903439826291436 -1.822232928037625\n",
      "\tgrad:  3.0 6.0 1.003668883531427 2.4690254534873137\n",
      "progress: 8 w= 1.6461098480030634 w_2= 0.10851402732513854 loss= 1.1271441571237342\n",
      "\tgrad:  1.0 2.0 -0.49075224934359607 -0.48093720435672394\n",
      "\tgrad:  2.0 4.0 -0.9786866461287111 -1.8007834288768336\n",
      "\tgrad:  3.0 6.0 0.9863628827437587 2.42645269154964\n",
      "progress: 9 w= 1.6509406081303488 w_2= 0.10706670674197771 loss= 1.0965821314716968\n",
      "\tgrad:  1.0 2.0 -0.48398537025534694 -0.4743056628502398\n",
      "\tgrad:  2.0 4.0 -0.9648000914090993 -1.775232168192744\n",
      "\tgrad:  3.0 6.0 0.9740649222758879 2.3961997087986795\n",
      "progress: 10 w= 1.6556878135242343 w_2= 0.10560008796442075 loss= 1.0669579358015013\n",
      "\tgrad:  1.0 2.0 -0.4774241970226898 -0.4678757130822362\n",
      "\tgrad:  2.0 4.0 -0.9518420345204213 -1.7513893435175767\n",
      "\tgrad:  3.0 6.0 0.960456445756595 2.3627228565612306\n",
      "progress: 11 w= 1.6603759113820993 w_2= 0.10416550996480656 loss= 1.0381006941258561\n",
      "\tgrad:  1.0 2.0 -0.47091715730618855 -0.46149881416006444\n",
      "\tgrad:  2.0 4.0 -0.9388313666561956 -1.727449714647399\n",
      "\tgrad:  3.0 6.0 0.9474908828466013 2.330827571802635\n",
      "progress: 12 w= 1.664998487793257 w_2= 0.10274671953485484 loss= 1.0100341186272406\n",
      "\tgrad:  1.0 2.0 -0.4645095853437762 -0.45521939363690045\n",
      "\tgrad:  2.0 4.0 -0.9260687152868581 -1.7039664361278177\n",
      "\tgrad:  3.0 6.0 0.9345600773472533 2.299017790274263\n",
      "progress: 13 w= 1.6695586700260912 w_2= 0.10134839992975939 loss= 0.9827232529943309\n",
      "\tgrad:  1.0 2.0 -0.4581858600882991 -0.4490221428865331\n",
      "\tgrad:  2.0 4.0 -0.9134578292462106 -1.6807624058130273\n",
      "\tgrad:  3.0 6.0 0.9218491770546215 2.267748975554376\n",
      "progress: 14 w= 1.67405661514889 w_2= 0.09996875566121123 loss= 0.9561518111537894\n",
      "\tgrad:  1.0 2.0 -0.4519492583797975 -0.44291027321220167\n",
      "\tgrad:  2.0 4.0 -0.9010254038451642 -1.6578867430751032\n",
      "\tgrad:  3.0 6.0 0.9092977063810643 2.236872357697411\n",
      "progress: 15 w= 1.678493384707329 w_2= 0.09860800224711017 loss= 0.9302985330925462\n",
      "\tgrad:  1.0 2.0 -0.44579722609112205 -0.4368812815692995\n",
      "\tgrad:  2.0 4.0 -0.8887601032492274 -1.6353185899785778\n",
      "\tgrad:  3.0 6.0 0.8969212959929855 2.206426388142745\n",
      "progress: 16 w= 1.6828697450408026 w_2= 0.09726573708116149 loss= 0.9051443874943702\n",
      "\tgrad:  1.0 2.0 -0.4397290357560717 -0.4309344550409504\n",
      "\tgrad:  2.0 4.0 -0.8766624107079579 -1.6130588357026419\n",
      "\tgrad:  3.0 6.0 0.8847120504822286 2.1763916441862765\n",
      "progress: 17 w= 1.6871865390006204 w_2= 0.09594175354673465 loss= 0.8806703524416937\n",
      "\tgrad:  1.0 2.0 -0.4337434149052899 -0.42506854660718396\n",
      "\tgrad:  2.0 4.0 -0.8647291905977088 -1.5911017106997853\n",
      "\tgrad:  3.0 6.0 0.8726694014711391 2.146766727619017\n",
      "progress: 18 w= 1.691444571040939 w_2= 0.09463578884361418 loss= 0.8568580746609913\n",
      "\tgrad:  1.0 2.0 -0.4278392802308937 -0.41928249462627587\n",
      "\tgrad:  2.0 4.0 -0.8529584686159861 -1.5694435822534132\n",
      "\tgrad:  3.0 6.0 0.8607905525995392 2.1175447593948817\n",
      "progress: 19 w= 1.6956446430034124 w_2= 0.09334760201846225 loss= 0.8336896499926815\n",
      "\tgrad:  1.0 2.0 -0.4220155099562506 -0.41357519975712576\n",
      "\tgrad:  2.0 4.0 -0.8413479509196655 -1.5480802296921858\n",
      "\tgrad:  3.0 6.0 0.8490734379186726 2.088720657279957\n",
      "progress: 20 w= 1.6997875432329848 w_2= 0.09207694974015579 loss= 0.8111476727827825\n",
      "\tgrad:  1.0 2.0 -0.41627101405371914 -0.40794559377264417\n",
      "\tgrad:  2.0 4.0 -0.8298954821657087 -1.5270076871849056\n",
      "\tgrad:  3.0 6.0 0.8375158051987128 2.0602888807888284\n",
      "progress: 21 w= 1.703874050143192 w_2= 0.09082359374184301 loss= 0.7892152036073709\n",
      "\tgrad:  1.0 2.0 -0.41060471222993034 -0.4023926179853312\n",
      "\tgrad:  2.0 4.0 -0.8185989031289296 -1.5062219817572284\n",
      "\tgrad:  3.0 6.0 0.826115499262551 2.0322441281858854\n",
      "progress: 22 w= 1.707904931304155 w_2= 0.08958729845740976 loss= 0.7678757624078734\n",
      "\tgrad:  1.0 2.0 -0.4050155404768705 -0.39691522966733306\n",
      "\tgrad:  2.0 4.0 -0.80745609426328 -1.4857192134444404\n",
      "\tgrad:  3.0 6.0 0.8148703737085015 2.0045811193229213\n",
      "progress: 23 w= 1.7118809439144713 w_2= 0.08836783169529827 loss= 0.7471133143165434\n",
      "\tgrad:  1.0 2.0 -0.3995024487804608 -0.39151239980485153\n",
      "\tgrad:  2.0 4.0 -0.796464961688244 -1.46549552950637\n",
      "\tgrad:  3.0 6.0 0.8037783177190168 1.977294661588795\n",
      "progress: 24 w= 1.7158028348419683 w_2= 0.08716496437252254 loss= 0.7269122581547537\n",
      "\tgrad:  1.0 2.0 -0.3940644015710184 -0.3861831135395981\n",
      "\tgrad:  2.0 4.0 -0.785623441011877 -1.4455471314618542\n",
      "\tgrad:  3.0 6.0 0.792837247237351 1.9503796282038657\n",
      "progress: 25 w= 1.7196713407954236 w_2= 0.0859784705404984 loss= 0.7072574145429201\n",
      "\tgrad:  1.0 2.0 -0.3887003773281559 -0.38092636978159256\n",
      "\tgrad:  2.0 4.0 -0.7749294956373287 -1.4258702719726841\n",
      "\tgrad:  3.0 6.0 0.7820451071856418 1.923830963676668\n",
      "progress: 26 w= 1.7234871884532221 w_2= 0.08480812732127449 loss= 0.6881340145455354\n",
      "\tgrad:  1.0 2.0 -0.3834093684510069 -0.37574118108198684\n",
      "\tgrad:  2.0 4.0 -0.7643811167846337 -1.4064612548837232\n",
      "\tgrad:  3.0 6.0 0.7713998702707183 1.8976436808659578\n",
      "progress: 27 w= 1.7272510946028712 w_2= 0.08365371487227201 loss= 0.6695276885579873\n",
      "\tgrad:  1.0 2.0 -0.3781903810497136 -0.3706265734287193\n",
      "\tgrad:  2.0 4.0 -0.7539763229881054 -1.3873164342981141\n",
      "\tgrad:  3.0 6.0 0.7608995368536675 1.8718128606600253\n",
      "progress: 28 w= 1.7309637662747126 w_2= 0.08251501634294008 loss= 0.6514244555137865\n",
      "\tgrad:  1.0 2.0 -0.3730424347646948 -0.3655815860694007\n",
      "\tgrad:  2.0 4.0 -0.7437131597629776 -1.368432213963878\n",
      "\tgrad:  3.0 6.0 0.7505421344965431 1.8463336508615065\n",
      "progress: 29 w= 1.734625900875024 w_2= 0.0813918178346578 loss= 0.633810712377533\n",
      "\tgrad:  1.0 2.0 -0.3679645625806365 -0.36060527132902376\n",
      "\tgrad:  2.0 4.0 -0.7335896992261883 -1.3498050465761864\n",
      "\tgrad:  3.0 6.0 0.7403257176159972 1.821201265335345\n",
      "progress: 30 w= 1.7382381863169323 w_2= 0.08028390836035645 loss= 0.6166732239238419\n",
      "\tgrad:  1.0 2.0 -0.3629558106454227 -0.35569669443251417\n",
      "\tgrad:  2.0 4.0 -0.723604039738003 -1.3314314331179204\n",
      "\tgrad:  3.0 6.0 0.7302483671102831 1.7964109830912864\n",
      "progress: 31 w= 1.7418013011496638 w_2= 0.07919107980494794 loss= 0.5999991127920598\n",
      "\tgrad:  1.0 2.0 -0.3580152380907764 -0.3508549333289608\n",
      "\tgrad:  2.0 4.0 -0.7137543055436257 -1.31330792220027\n",
      "\tgrad:  3.0 6.0 0.7203081900011199 1.7719581474027422\n",
      "progress: 32 w= 1.7453159146859967 w_2= 0.07811312688621282 loss= 0.583775849810075\n",
      "\tgrad:  1.0 2.0 -0.35314191685558116 -0.34607907851846953\n",
      "\tgrad:  2.0 4.0 -0.7040386464212194 -1.2954311094150448\n",
      "\tgrad:  3.0 6.0 0.710503319077354 1.7478381649302754\n",
      "progress: 33 w= 1.748782687127991 w_2= 0.07704984711624521 loss= 0.5679912445796961\n",
      "\tgrad:  1.0 2.0 -0.3483349315115274 -0.34136823288129703\n",
      "\tgrad:  2.0 4.0 -0.6944552373342194 -1.277797636694963\n",
      "\tgrad:  3.0 6.0 0.7008319125444924 1.7240465048594587\n",
      "progress: 34 w= 1.7522022696910036 w_2= 0.07600104076341323 loss= 0.5526334363166109\n",
      "\tgrad:  1.0 2.0 -0.3435933790911663 -0.33672151150934315\n",
      "\tgrad:  2.0 4.0 -0.6850022780885716 -1.260404191682973\n",
      "\tgrad:  3.0 6.0 0.6912921536785799 1.7005786980492985\n",
      "progress: 35 w= 1.755575304726015 w_2= 0.0749665108148434 loss= 0.5376908849380246\n",
      "\tgrad:  1.0 2.0 -0.33891636891828325 -0.33213804153991777\n",
      "\tgrad:  2.0 4.0 -0.6756779929945367 -1.243247507109949\n",
      "\tgrad:  3.0 6.0 0.6818822504850477 1.6774303361932112\n",
      "progress: 36 w= 1.7589024258402925 w_2= 0.07394606293940995 loss= 0.5231523623912611\n",
      "\tgrad:  1.0 2.0 -0.33430302244059495 -0.32761696199178303\n",
      "\tgrad:  2.0 4.0 -0.666480630533167 -1.226324360181028\n",
      "\tgrad:  3.0 6.0 0.6726004353620016 1.6545970709905173\n",
      "progress: 37 w= 1.7621842580164102 w_2= 0.07293950545123289 loss= 0.5090069442168484\n",
      "\tgrad:  1.0 2.0 -0.32975247306471367 -0.3231574236034196\n",
      "\tgrad:  2.0 4.0 -0.6574084630272683 -1.2096315719701742\n",
      "\tgrad:  3.0 6.0 0.663444964768253 1.6320746133299107\n",
      "progress: 38 w= 1.7654214177296474 w_2= 0.07194664927366971 loss= 0.49524400133971674\n",
      "\tgrad:  1.0 2.0 -0.32526386599336554 -0.31875858867349827\n",
      "\tgrad:  2.0 4.0 -0.6484597863168755 -1.193166006823052\n",
      "\tgrad:  3.0 6.0 0.6544141188957937 1.609858732483655\n",
      "progress: 39 w= 1.7686145130637918 w_2= 0.07096730790379865 loss= 0.48185319208235555\n",
      "\tgrad:  1.0 2.0 -0.320836358064819 -0.31441963090352276\n",
      "\tgrad:  2.0 4.0 -0.6396329194391388 -1.1769245717680157\n",
      "\tgrad:  3.0 6.0 0.6455062013467217 1.58794525531294\n",
      "progress: 40 w= 1.7717641438253642 w_2= 0.07000129737738464 loss= 0.46882445439392145\n",
      "\tgrad:  1.0 2.0 -0.31646911759450225 -0.31013973524261207\n",
      "\tgrad:  2.0 4.0 -0.6309262043125532 -1.1609042159350977\n",
      "\tgrad:  3.0 6.0 0.6367195388145621 1.56633006548382\n",
      "progress: 41 w= 1.7748709016562891 w_2= 0.06904843623432354 loss= 0.45614799828947017\n",
      "\tgrad:  1.0 2.0 -0.3121613242187746 -0.30591809773439893\n",
      "\tgrad:  2.0 4.0 -0.6223380054255045 -1.1451019299829284\n",
      "\tgrad:  3.0 6.0 0.6280524807700019 1.545009102694216\n",
      "progress: 42 w= 1.777935370145032 w_2= 0.06810854548455465 loss= 0.4438142984936158\n",
      "\tgrad:  1.0 2.0 -0.3079121687408266 -0.3017539253660102\n",
      "\tgrad:  2.0 4.0 -0.6138667095290415 -1.129514745533438\n",
      "\tgrad:  3.0 6.0 0.6195033991508012 1.5239783619109755\n",
      "progress: 43 w= 1.7809581249362225 w_2= 0.06718144857443938 loss= 0.4318140872830992\n",
      "\tgrad:  1.0 2.0 -0.30372085297867635 -0.2976464359191029\n",
      "\tgrad:  2.0 4.0 -0.6055107253338399 -1.114139734614266\n",
      "\tgrad:  3.0 6.0 0.6110706880560013 1.503233892617784\n",
      "progress: 44 w= 1.7839397338387877 w_2= 0.06626697135359524 loss= 0.4201383475228846\n",
      "\tgrad:  1.0 2.0 -0.2995865896152341 -0.29359485782292927\n",
      "\tgrad:  2.0 4.0 -0.5972684832112876 -1.0989740091087654\n",
      "\tgrad:  3.0 6.0 0.602752763444208 1.4827717980727524\n",
      "progress: 45 w= 1.7868807569326108 w_2= 0.06536494204218465 loss= 0.40877830589055214\n",
      "\tgrad:  1.0 2.0 -0.29550860205040896 -0.2895984300094008\n",
      "\tgrad:  2.0 4.0 -0.5891384348986222 -1.0840147202134638\n",
      "\tgrad:  3.0 6.0 0.5945480628361395 1.4625882345769057\n",
      "progress: 46 w= 1.7897817466737398 w_2= 0.06447519119864424 loss= 0.39772542628389285\n",
      "\tgrad:  1.0 2.0 -0.2914861242552318 -0.2856564017701273\n",
      "\tgrad:  2.0 4.0 -0.5811190532081358 -1.0692590579029684\n",
      "\tgrad:  3.0 6.0 0.5864550450209887 1.4426794107516248\n",
      "progress: 47 w= 1.7926432479981635 w_2= 0.06359755168785895 loss= 0.3869714034067597\n",
      "\tgrad:  1.0 2.0 -0.2875184006279552 -0.2817680326153962\n",
      "\tgrad:  2.0 4.0 -0.5732088317402493 -1.0547042504020574\n",
      "\tgrad:  3.0 6.0 0.5784721897670284 1.423041586826896\n",
      "progress: 48 w= 1.7954657984241753 w_2= 0.06273185864976455 loss= 0.37650815652834024\n",
      "\tgrad:  1.0 2.0 -0.2836046858521204 -0.27793259213507815\n",
      "\tgrad:  2.0 4.0 -0.5654062846005825 -1.0403475636650725\n",
      "\tgrad:  3.0 6.0 0.5705979975360052 1.4036710739385772\n",
      "progress: 49 w= 1.7982499281533422 w_2= 0.061877949468380294 loss= 0.3663278234111841\n",
      "\tgrad:  1.0 2.0 -0.279744244756555 -0.27414935986142375\n",
      "\tgrad:  2.0 4.0 -0.5577099461208253 -1.0261863008623173\n",
      "\tgrad:  3.0 6.0 0.5628309892014443 1.38456423343556\n",
      "progress: 50 w= 1.8009961601701017 w_2= 0.061035663741262104 loss= 0.3564227544033945\n",
      "\tgrad:  1.0 2.0 -0.2759363521772724 -0.27041762513372714\n",
      "\tgrad:  2.0 4.0 -0.5501183705834158 -1.0122178018734864\n",
      "\tgrad:  3.0 6.0 0.5551697057708029 1.3657174761961723\n",
      "progress: 51 w= 1.8037050103400003 w_2= 0.06020484324937252 loss= 0.34678550669057395\n",
      "\tgrad:  1.0 2.0 -0.27218029282125444 -0.26673668696482933\n",
      "\tgrad:  2.0 4.0 -0.5426301319499647 -0.9984394427879337\n",
      "\tgrad:  3.0 6.0 0.5476127081114335 1.3471272619541264\n",
      "progress: 52 w= 1.8063769875065983 w_2= 0.05938533192735888 loss= 0.33740883870318034\n",
      "\tgrad:  1.0 2.0 -0.2684753611320856 -0.26310585390944397\n",
      "\tgrad:  2.0 4.0 -0.5352438235933938 -0.9848486354118435\n",
      "\tgrad:  3.0 6.0 0.5401585766802341 1.3287900986333696\n",
      "progress: 53 w= 1.8090125935870507 w_2= 0.05857697583423806 loss= 0.32828570467510565\n",
      "\tgrad:  1.0 2.0 -0.26482086115742254 -0.2595244439342741\n",
      "\tgrad:  2.0 4.0 -0.5279580580337075 -0.9714428267820203\n",
      "\tgrad:  3.0 6.0 0.5328059112569719 1.3107025416921463\n",
      "progress: 54 w= 1.8116123236663924 w_2= 0.05777962312447954 loss= 0.3194092493493853\n",
      "\tgrad:  1.0 2.0 -0.2612161064182561 -0.2559917842898911\n",
      "\tgrad:  2.0 4.0 -0.5207714666773455 -0.9582194986863151\n",
      "\tgrad:  3.0 6.0 0.5255533306813192 1.2928611934760426\n",
      "progress: 55 w= 1.8141766660905352 w_2= 0.05699312401948117 loss= 0.3107728028270564\n",
      "\tgrad:  1.0 2.0 -0.25766041977996723 -0.2525072113843678\n",
      "\tgrad:  2.0 4.0 -0.5136826995601229 -0.9451761671906276\n",
      "\tgrad:  3.0 6.0 0.5183994725933285 1.2752627025795853\n",
      "progress: 56 w= 1.8167061025580027 w_2= 0.056217330779435276 loss= 0.3023698755552971\n",
      "\tgrad:  1.0 2.0 -0.2541531333251239 -0.2490700706586213\n",
      "\tgrad:  2.0 4.0 -0.506690425093625 -0.9323103821722718\n",
      "\tgrad:  3.0 6.0 0.5113429931776103 1.2579037632169054\n",
      "progress: 57 w= 1.819201108210414 w_2= 0.05545209767557516 loss= 0.29419415345108224\n",
      "\tgrad:  1.0 2.0 -0.25069358822802146 -0.24567971646346098\n",
      "\tgrad:  2.0 4.0 -0.4997933298150894 -0.9196197268597643\n",
      "\tgrad:  3.0 6.0 0.5043825669108148 1.240781114600603\n",
      "progress: 58 w= 1.821662151721737 w_2= 0.05469728096280138 loss= 0.2862394931566868\n",
      "\tgrad:  1.0 2.0 -0.24728113463092294 -0.24233551193830438\n",
      "\tgrad:  2.0 4.0 -0.4929901181406784 -0.9071018173788481\n",
      "\tgrad:  3.0 6.0 0.4975168863126953 1.2238915403292285\n",
      "progress: 59 w= 1.8240896953863261 w_2= 0.05395273885268063 loss= 0.27849991742347974\n",
      "\tgrad:  1.0 2.0 -0.24391513152198652 -0.23903682889154698\n",
      "\tgrad:  2.0 4.0 -0.4862795121220955 -0.8947543023046549\n",
      "\tgrad:  3.0 6.0 0.4907446617005071 1.2072318677832552\n",
      "progress: 60 w= 1.8264841952057618 w_2= 0.0532183314868101 loss= 0.27096961062052943\n",
      "\tgrad:  1.0 2.0 -0.24059494661485648 -0.23578304768255887\n",
      "\tgrad:  2.0 4.0 -0.4796602512065462 -0.8825748622200464\n",
      "\tgrad:  3.0 6.0 0.4840646209467163 1.1907989675289148\n",
      "progress: 61 w= 1.8288461009745085 w_2= 0.052493920910547 loss= 0.26364291436465304\n",
      "\tgrad:  1.0 2.0 -0.23731995622988888 -0.23257355710529115\n",
      "\tgrad:  2.0 4.0 -0.4731310919999423 -0.8705612092798951\n",
      "\tgrad:  3.0 6.0 0.47747550924006 1.1745897527305402\n",
      "progress: 62 w= 1.831175856364406 w_2= 0.05177937104709346 loss= 0.2565143232686249\n",
      "\tgrad:  1.0 2.0 -0.23408954517700087 -0.22940775427346072\n",
      "\tgrad:  2.0 4.0 -0.4666908080333414 -0.8587110867813479\n",
      "\tgrad:  3.0 6.0 0.4709760888498149 1.1586011785705495\n",
      "progress: 63 w= 1.8334738990080115 w_2= 0.051074547671936046 loss= 0.2495784808043458\n",
      "\tgrad:  1.0 2.0 -0.23090310664010483 -0.22628504450730258\n",
      "\tgrad:  2.0 4.0 -0.46033818953255334 -0.8470222687398987\n",
      "\tgrad:  3.0 6.0 0.46456513889332207 1.1428302416775669\n",
      "progress: 64 w= 1.8357406605808049 w_2= 0.05037931838763239 loss= 0.24283017527787293\n",
      "\tgrad:  1.0 2.0 -0.2277600420631254 -0.2232048412218628\n",
      "\tgrad:  2.0 4.0 -0.45407204319089445 -0.8354925594712448\n",
      "\tgrad:  3.0 6.0 0.4582414551066396 1.1272739795623306\n",
      "progress: 65 w= 1.8379765668822787 w_2= 0.04969355259894016 loss= 0.23626433591327473\n",
      "\tgrad:  1.0 2.0 -0.22465976103756224 -0.22016656581681104\n",
      "\tgrad:  2.0 4.0 -0.4478911919450326 -0.8241197931788591\n",
      "\tgrad:  3.0 6.0 0.45200384961831297 1.1119294700610496\n",
      "progress: 66 w= 1.8401820379159215 w_2= 0.049017121488286367 loss= 0.2298760290423716\n",
      "\tgrad:  1.0 2.0 -0.2216016811915842 -0.21716964756775248\n",
      "\tgrad:  2.0 4.0 -0.4417944747538787 -0.8129018335471372\n",
      "\tgrad:  3.0 6.0 0.44585115072627346 1.096793830786627\n",
      "progress: 67 w= 1.8423574879681133 w_2= 0.048349897991568996 loss= 0.2236604543975124\n",
      "\tgrad:  1.0 2.0 -0.2185852280806353 -0.21421352351902279\n",
      "\tgrad:  2.0 4.0 -0.43578074638049635 -0.8018365733401147\n",
      "\tgrad:  3.0 6.0 0.43978220267769963 1.0818642185871408\n",
      "progress: 68 w= 1.8445033256859473 w_2= 0.047691756774288954 loss= 0.2176129415045749\n",
      "\tgrad:  1.0 2.0 -0.21560983507952747 -0.2112976383779368\n",
      "\tgrad:  2.0 4.0 -0.4298488771769655 -0.7909219340056168\n",
      "\tgrad:  3.0 6.0 0.43379586545194293 1.0671378290117914\n",
      "progress: 69 w= 1.846619954153993 w_2= 0.047042574208006574 loss= 0.21172894617350885\n",
      "\tgrad:  1.0 2.0 -0.21267494327600112 -0.20842144441048127\n",
      "\tgrad:  2.0 4.0 -0.42399775287219477 -0.7801558652848399\n",
      "\tgrad:  3.0 6.0 0.4278910145463737 1.052611895784091\n",
      "progress: 70 w= 1.848707770970011 w_2= 0.04640222834711887 loss= 0.2060040470837633\n",
      "\tgrad:  1.0 2.0 -0.20978000136574027 -0.2055844013384256\n",
      "\tgrad:  2.0 4.0 -0.4182262743626026 -0.7695363448271877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:  3.0 6.0 0.4220665407651474 1.0382836902822632\n",
      "progress: 71 w= 1.850767168319643 w_2= 0.045770598905952364 loss= 0.20043394246204002\n",
      "\tgrad:  1.0 2.0 -0.20692446554880917 -0.20278597623783323\n",
      "\tgrad:  2.0 4.0 -0.41253335750566045 -0.7590613778104149\n",
      "\tgrad:  3.0 6.0 0.41632135001085935 1.0241505210267245\n",
      "progress: 72 w= 1.8527985330500791 w_2= 0.0451475672361676 loss= 0.19501444684987743\n",
      "\tgrad:  1.0 2.0 -0.20410779942750645 -0.20002564343895646\n",
      "\tgrad:  2.0 4.0 -0.40691793291625267 -0.7487289965659052\n",
      "\tgrad:  3.0 6.0 0.41065436307897585 1.0102097331742819\n",
      "progress: 73 w= 1.854802246742727 w_2= 0.0445330163044734 loss= 0.18974148795863943\n",
      "\tgrad:  1.0 2.0 -0.20132947390559908 -0.1973028844274869\n",
      "\tgrad:  2.0 4.0 -0.4013789457657637 -0.7385372602090037\n",
      "\tgrad:  3.0 6.0 0.4050645154552015 0.9964587080197944\n",
      "progress: 74 w= 1.8567786857848887 w_2= 0.04392683067064036 loss= 0.18461110360953278\n",
      "\tgrad:  1.0 2.0 -0.1985889670889418 -0.1946171877471632\n",
      "\tgrad:  2.0 4.0 -0.39591535558398405 -0.7284842542745302\n",
      "\tgrad:  3.0 6.0 0.3995507571154153 0.9828948625039278\n",
      "progress: 75 w= 1.8587282214404637 w_2= 0.043328896465818015 loss= 0.17961943875637182\n",
      "\tgrad:  1.0 2.0 -0.19588576418743653 -0.1919680489036879\n",
      "\tgrad:  2.0 4.0 -0.3905261360636185 -0.7185680903570564\n",
      "\tgrad:  3.0 6.0 0.3941120523285111 0.9695156487281338\n",
      "progress: 76 w= 1.8606512199196892 w_2= 0.042739101371144124 loss= 0.17476274258883764\n",
      "\tgrad:  1.0 2.0 -0.19321935741833318 -0.1893549702699664\n",
      "\tgrad:  2.0 4.0 -0.3852102748675179 -0.7087869057562344\n",
      "\tgrad:  3.0 6.0 0.3887473794617904 0.9563185534759935\n",
      "progress: 77 w= 1.8625480424479297 w_2= 0.042157334596646195 loss= 0.17003736571406539\n",
      "\tgrad:  1.0 2.0 -0.19058924591084825 -0.18677746099263137\n",
      "\tgrad:  2.0 4.0 -0.37996677343853413 -0.6991388631269011\n",
      "\tgrad:  3.0 6.0 0.3834557307890627 0.9433010977410987\n",
      "progress: 78 w= 1.864419045333533 w_2= 0.041583486860430535 loss= 0.16543975741443545\n",
      "\tgrad:  1.0 2.0 -0.18799493561207292 -0.18423503689983134\n",
      "\tgrad:  2.0 4.0 -0.37479464681190855 -0.6896221501339106\n",
      "\tgrad:  3.0 6.0 0.37823611230138354 0.9304608362613926\n",
      "progress: 79 w= 1.866264580034759 w_2= 0.04101745036815402 loss= 0.16096646297951434\n",
      "\tgrad:  1.0 2.0 -0.185435939194174 -0.18172722041029044\n",
      "\tgrad:  2.0 4.0 -0.36969292343028215 -0.6802349791117202\n",
      "\tgrad:  3.0 6.0 0.3730875435202705 0.9177953570598572\n",
      "progress: 80 w= 1.8680849932258008 w_2= 0.04045911879277555 loss= 0.1566141211101332\n",
      "\tgrad:  1.0 2.0 -0.18291177596284713 -0.17925354044359\n",
      "\tgrad:  2.0 4.0 -0.364660644961182 -0.6709755867285736\n",
      "\tgrad:  3.0 6.0 0.36800905731358924 0.9053022809914353\n",
      "progress: 81 w= 1.8698806268619055 w_2= 0.03990838725458283 loss= 0.15237946139265623\n",
      "\tgrad:  1.0 2.0 -0.18042197176702324 -0.17681353233168284\n",
      "\tgrad:  2.0 4.0 -0.3596968661169999 -0.6618422336552783\n",
      "\tgrad:  3.0 6.0 0.3629996997138587 0.8929792612960927\n",
      "progress: 82 w= 1.8716518182436073 w_2= 0.03936515230149151 loss= 0.14825930184154804\n",
      "\tgrad:  1.0 2.0 -0.17796605890980244 -0.1744067377316063\n",
      "\tgrad:  2.0 4.0 -0.3548006544774367 -0.6528332042384832\n",
      "\tgrad:  3.0 6.0 0.35805852973902397 0.8808239831580025\n",
      "progress: 83 w= 1.8733989000800895 w_2= 0.03882931188961238 loss= 0.14425054650838054\n",
      "\tgrad:  1.0 2.0 -0.17554357606059634 -0.17203270453938435\n",
      "\tgrad:  2.0 4.0 -0.3499710903143374 -0.6439468061783806\n",
      "\tgrad:  3.0 6.0 0.35318461921576016 0.8688341632707726\n",
      "progress: 84 w= 1.8751222005516812 w_2= 0.038300765364082306 loss= 0.14035018315549075\n",
      "\tgrad:  1.0 2.0 -0.1731540681684729 -0.16969098680510353\n",
      "\tgrad:  2.0 4.0 -0.34520726641893873 -0.635181370210848\n",
      "\tgrad:  3.0 6.0 0.34837705260505203 0.8570075494084453\n",
      "progress: 85 w= 1.8768220433715048 w_2= 0.037779413440157374 loss= 0.13655528099254263\n",
      "\tgrad:  1.0 2.0 -0.17079708637667546 -0.16738114464914178\n",
      "\tgrad:  2.0 4.0 -0.3405082879314456 -0.6265352497938608\n",
      "\tgrad:  3.0 6.0 0.3436349268302674 0.8453419200024594\n",
      "progress: 86 w= 1.8784987478462833 w_2= 0.0372651581845628 loss= 0.13286298847428915\n",
      "\tgrad:  1.0 2.0 -0.16847218793830754 -0.16510274417954118\n",
      "\tgrad:  2.0 4.0 -0.33587327217293605 -0.6180068207982039\n",
      "\tgrad:  3.0 6.0 0.3389573511074957 0.8338350837244484\n",
      "progress: 87 w= 1.8801526289363208 w_2= 0.03675790299709577 loss= 0.12927053115787662\n",
      "\tgrad:  1.0 2.0 -0.16617893613316692 -0.1628553574105034\n",
      "\tgrad:  2.0 4.0 -0.3313013484795668 -0.6095944812024037\n",
      "\tgrad:  3.0 6.0 0.3343434467782096 0.822484879074409\n",
      "progress: 88 w= 1.8817839973146662 w_2= 0.03625755259248075 loss= 0.12577520961808955\n",
      "\tgrad:  1.0 2.0 -0.16391690018570637 -0.16063856218199213\n",
      "\tgrad:  2.0 4.0 -0.3267916580390029 -0.6012966507917668\n",
      "\tgrad:  3.0 6.0 0.3297923471442292 0.8112891739748029\n",
      "progress: 89 w= 1.883393159425471 w_2= 0.03576401298247031 loss= 0.12237439741896278\n",
      "\tgrad:  1.0 2.0 -0.16168565518411748 -0.15845194208043534\n",
      "\tgrad:  2.0 4.0 -0.32234335372911005 -0.5931117708615616\n",
      "\tgrad:  3.0 6.0 0.32530319730493495 0.8002458653701403\n",
      "progress: 90 w= 1.8849804175415539 w_2= 0.03527719145818888 loss= 0.11906553914023758\n",
      "\tgrad:  1.0 2.0 -0.15948478200051452 -0.15629508636050415\n",
      "\tgrad:  2.0 4.0 -0.3179555999588253 -0.5850383039242395\n",
      "\tgrad:  3.0 6.0 0.32087515399661193 0.7893528788316644\n",
      "progress: 91 w= 1.8865460698211811 w_2= 0.034796996572719674 loss= 0.11584614845718265\n",
      "\tgrad:  1.0 2.0 -0.1573138672121983 -0.1541675898679542\n",
      "\tgrad:  2.0 4.0 -0.3136275725111872 -0.5770747334205844\n",
      "\tgrad:  3.0 6.0 0.3165073854341447 0.7786081681679988\n",
      "progress: 92 w= 1.8880904103640737 w_2= 0.034323338123925067 loss= 0.11271380627233274\n",
      "\tgrad:  1.0 2.0 -0.15517250302400276 -0.1520690529635229\n",
      "\tgrad:  2.0 4.0 -0.3093584583885267 -0.5692195634348884\n",
      "\tgrad:  3.0 6.0 0.31219907115467294 0.7680097150404954\n",
      "progress: 93 w= 1.8896137292666522 w_2= 0.03385612713750422 loss= 0.10966615889774368\n",
      "\tgrad:  1.0 2.0 -0.1530602871916873 -0.14999908144785357\n",
      "\tgrad:  2.0 4.0 -0.3051474556597231 -0.56147131841389\n",
      "\tgrad:  3.0 6.0 0.30794940186356 0.7575555285843691\n",
      "progress: 94 w= 1.8911163126765307 w_2= 0.03339527585027796 loss= 0.106700916286395\n",
      "\tgrad:  1.0 2.0 -0.1509768229463826 -0.147957286487455\n",
      "\tgrad:  2.0 4.0 -0.3009937733096031 -0.5538285428896685\n",
      "\tgrad:  3.0 6.0 0.3037575792822853 0.7472436450344215\n",
      "progress: 95 w= 1.8925984428462677 w_2= 0.03294069769370499 loss= 0.1038158503114179\n",
      "\tgrad:  1.0 2.0 -0.14892171892005468 -0.14594328454165373\n",
      "\tgrad:  2.0 4.0 -0.29689663109031095 -0.5462898012061714\n",
      "\tgrad:  3.0 6.0 0.2996228159985801 0.7370721273565035\n",
      "progress: 96 w= 1.8940603981863855 w_2= 0.032492307277618204 loss= 0.10100879309184488\n",
      "\tgrad:  1.0 2.0 -0.1468945890719926 -0.1439566972905526\n",
      "\tgrad:  2.0 4.0 -0.2928552593747771 -0.5388536772495911\n",
      "\tgrad:  3.0 6.0 0.29554433531841795 0.7270390648833107\n",
      "progress: 97 w= 1.895502453317669 w_2= 0.032050020374186534 loss= 0.0982776353636337\n",
      "\tgrad:  1.0 2.0 -0.1448950526162891 -0.14199715156396353\n",
      "\tgrad:  2.0 4.0 -0.28886889901212776 -0.5315187741823166\n",
      "\tgrad:  3.0 6.0 0.2915213711202167 0.7171425729557424\n",
      "progress: 98 w= 1.8969248791227509 w_2= 0.03161375390209191 loss= 0.09562032489473567\n",
      "\tgrad:  1.0 2.0 -0.1429227339503143 -0.14006427927130805\n",
      "\tgrad:  2.0 4.0 -0.28493680118508813 -0.5242837141805623\n",
      "\tgrad:  3.0 6.0 0.2875531677108576 0.7073807925687206\n",
      "progress: 99 w= 1.8983279427969963 w_2= 0.03118342591092341 loss= 0.09303486494301748\n",
      "predict(after training) 4 hours 7.593311771187985\n"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "print(\"predict (before training)\", 4, forward(4))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad_1 = gradient_1(x_val, y_val)\n",
    "        w = w - 0.01 * grad_1 # where we have to update\n",
    "        grad_2 = gradient_2(x_val, y_val)\n",
    "        w_2 = w_2 - 0.01 * grad_2 # where we have to update\n",
    "        print(\"\\tgrad: \", x_val, y_val, grad_1, grad_2)\n",
    "        l = loss(x_val, y_val)\n",
    "\n",
    "    print(\"progress:\", epoch, \"w=\", w, \"w_2=\", w_2, \"loss=\", l)\n",
    "\n",
    "# After training\n",
    "print(\"predict(after training)\", \"4 hours\", forward(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_64",
   "language": "python",
   "name": "py37_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
